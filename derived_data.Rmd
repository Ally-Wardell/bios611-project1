---
title: 'BIOS 611 PROJECT: DATA SUMMARY'
author: "Ally Wardell"
date: "10/22/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library('tidyverse')
library('readr')
library('flextable')
library('gtsummary')
library('webshot')
library('caret')
library('e1071')
library('randomForest')
```

## IMPORT DATASET, CHECK FOR MISSINGNESS, CLEAN IF NECESSARY

```{r import}
# remove missing values for the timebeing. 
heart_data <- read_csv("~/project/source_data/heart_data.csv",  na=c("", "NA", "?"))

#dichotomize target into presence or no presenece of heart disease. (target = 0 vs target=1-4)
derived_heart <- heart_data %>%
  mutate(Target=factor(ifelse(Target>1, 1, Target))) %>%
  select(-`...1`) %>%
  drop_na()
    
write_csv(derived_heart, "~/project/derived_data/derived_heart.csv" )

#heart_failure <- na.omit(read_csv("~/project/source_data/heart_failure.csv")) 
#creatine phosphokinase, ejection fraction, platelets, serumcreatinine, serum sodium, 
```

## Summarize the data. 

You can also embed plots, for example:

```{r pressure, echo=FALSE}
table_descriptive1 <- tbl_summary(data= derived_heart,
    by=Target,
    statistic= all_continuous() ~ "{mean} ({sd})",
       label = list(Age ~ "Age",
                 Sex ~ "Sex (M/F)",
                 Chest_Pain ~ "Chest Pain",
                 Resting_Blood_Pressure ~ "Resting Blood Pressure",
                 Colestrol ~ "Cholesterol",
                 Fasting_Blood_Sugar ~ "Fasting Blood Sugar",
                 Rest_ECG ~ "Resting ECG",
                 MAX_Heart_Rate ~ "Maximum Heart Rate",
                 Exercised_Induced_Angina ~ "Exercise Induced Angina",
                 ST_Depression ~ "Depression",
                 Slope ~ "Slope",
                 Major_Vessels ~ "Major Vessels",
                 Thalessemia ~ "Thalessemia"),
    
    missing='no')%>%
    add_n() %>%
    add_p(test = list(all_continuous() ~ "aov",
                      all_categorical() ~ "chisq.test")) %>%
    as_flex_table() %>%
    bold( bold = TRUE, part = "header") %>%
    add_header_lines(values="Summary Statistics for Heart Failure Covariates")
table_descriptive1

save_as_image(table_descriptive1, path = "/home/rstudio/project/table_descriptive1.png")

# 
# table_descriptive1 <- tbl_summary(data= heart_failure,
#     by=DEATH_EVENT,
#     statistic= all_continuous() ~ "{mean} ({sd})",
#        label = list(age ~ "Age",
#                  sex ~ "Sex (M/F)",
#                  anaemia ~ "Anaemia",
#                  diabetes ~ "Diabetes",
#                  high_blood_pressure  ~ "High Blood Pressure",
#                  smoking ~ "Smoking Status",
#                  creatinine_phosphokinase ~ "Creatinine Phosphokinase level (mcg/L)",
#                  ejection_fraction ~ "Ejection Fraction",
#                  platelets ~ "Platelet Counts (kiloplatelets/mL)",
#                  serum_creatinine ~ "Serum Creatinine (mg/dL)",
#                  serum_sodium ~ "Serum Sodium (mEq/L)",
#                  time ~ "Follow-up time" ),
#     
#     missing='no')%>%
#     add_n() %>%
#     add_p(test = list(all_continuous() ~ "aov",
#                       all_categorical() ~ "chisq.test")) %>%
#     as_flex_table() %>%
#     bold( bold = TRUE, part = "header") %>%
#     add_header_lines(values="Summary Statistics for Heart Failure Covariates")
# 
# save_as_image(table_descriptive1, path = "/home/rstudio/project/table_descriptive1.png")
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

``` {r}
set.seed(12)
tt_indices <- createFolds(derived_heart$Target, k=5)
error_per_fold <- list()
error_per_fold_regress <- list()
for(i in 1:5){
  train_data <-derived_heart[-tt_indices[[i]],]
  test_data <-derived_heart[tt_indices[[i]],]
  
  # Tune SVM
  tune_svm <- 
    tune(svm, Target~., data=train_data, kernel ="linear",
         ranges = list(gamma = 0.035, 
                       cost = 1:5,
                       epsilon = seq(from=0.1, to=0.5, by=0.1)))
  
  # Get best model
  svm_tuned <- tune_svm$best.model
  test_data$predict_svm <- predict(svm_tuned, newdata=test_data,
                                   type="response")
  
  # Create linear regression model
  lm_fit <- glm(Target~., data=train_data, family=binomial)
  test_data$predict_lm <- factor(ifelse(predict(lm_fit, newdata=test_data,
                                   type="response")>0.5,1,0))
  
  # Store MSE
  error_per_fold[[i]] <- confusionMatrix(data = test_data$predict_svm,
                                    reference = test_data$Target)$byClass
  error_per_fold_regress[[i]] <- confusionMatrix(data = test_data$predict_lm,
                                    reference = test_data$Target)$byClass
}
# Bind together, add MSE
error_all_folds <- do.call("rbind", error_per_fold)
error_all_folds_regress <- do.call("rbind", error_per_fold_regress)
error_all_folds_regress <- cbind(error_all_folds_regress)
                        #       "MSE"=(error_all_folds_regress[,"RMSE"])^2)
# Get mean and SE MSE
svm_cv_results <- 
  data.frame("Method"="svm",
             "CV_MSE"=apply(error_all_folds[,c("Sensitivity", "Specificity")], 
                                   MARGIN = 2, FUN = mean),
             "CV_MSE_SE"=apply(error_all_folds[,c("Sensitivity", 
                                                         "Specificity")], 
                                      MARGIN = 2, FUN = sd)) %>%
  rownames_to_column(var="Measure")
# Do same for regression
regress_cv_results <- 
  data.frame("Method"="lm",
             "CV_MSE"=
               apply(error_all_folds_regress[,c("Sensitivity", "Specificity")], 
                                   MARGIN = 2, FUN = mean),
             "CV_MSE_SE"=apply(error_all_folds_regress[,c("Sensitivity", 
                                                         "Specificity")], 
                                      MARGIN = 2, FUN = sd)) %>%
  rownames_to_column(var="Measure")
# Print results in flextable (not needed, but useful)
all_results <- rbind(svm_cv_results, regress_cv_results)
flextable(all_results)
```




``` {r}
set.seed(12)
tt_indices <- createFolds(y=derived_heart$Target, k=5)
error_per_fold <- list()
error_per_fold_regress <- list()
for(i in 1:5){
  train_data <- derived_heart[-tt_indices[[i]],]
  test_data <- derived_heart[tt_indices[[i]],]
  
  # Tune SVM
  tune_svm <- 
    tune(svm, Target~., data=train_data, kernel ="polynomial",
         ranges = list(gamma = c(0.001, 0.05, 0.1), 
                       cost = 1:3,
                       d = 2:3))
  
  # Get best model
  svm_tuned <- tune_svm$best.model
  test_data$predict_svm <- predict(svm_tuned, newdata=test_data,
                                   type="response")
  
  # Create linear regression model
  lm_fit <- glm(Target~., data=train_data, family=binomial)
  test_data$predict_lm <- factor(ifelse(predict(lm_fit, newdata=test_data,
                                   type="response")>0.5,1,0))
  
  # Store MSE
  error_per_fold[[i]] <- confusionMatrix(data = test_data$predict_svm,
                                    reference = test_data$Target)$byClass
  error_per_fold_regress[[i]] <- confusionMatrix(data = test_data$predict_lm,
                                    reference = test_data$Target)$byClass
}
# Bind together, add MSE
error_all_folds <- do.call("rbind", error_per_fold)
error_all_folds_regress <- do.call("rbind", error_per_fold_regress)
error_all_folds_regress <- cbind(error_all_folds_regress)
                            #   "MSE"=(error_all_folds_regress[,"RMSE"])^2)
# Get mean and SE MSE
svm_cv_results <- 
  data.frame("Method"="svm",
             "CV_MSE"=apply(error_all_folds[,c("Sensitivity", "Specificity")], 
                                   MARGIN = 2, FUN = mean),
             "CV_MSE_SE"=apply(error_all_folds[,c("Sensitivity", 
                                                         "Specificity")], 
                                      MARGIN = 2, FUN = sd)) %>%
  rownames_to_column(var="Measure")
# Do same for regression
regress_cv_results <- 
  data.frame("Method"="lm",
             "CV_MSE"=
               apply(error_all_folds_regress[,c("Sensitivity", "Specificity")], 
                                   MARGIN = 2, FUN = mean),
             "CV_MSE_SE"=apply(error_all_folds_regress[,c("Sensitivity", 
                                                         "Specificity")], 
                                      MARGIN = 2, FUN = sd)) %>%
  rownames_to_column(var="Measure")
# Print results in flextable (not needed, but useful)
all_results <- rbind(svm_cv_results, regress_cv_results)
flextable(all_results)
```


``` {r}
individualfolds<- createFolds(y=derived_heart$Target, k=5)
per_class_accuracy <- list()
    for(i in 1:length(individualfolds)){
      heart_train <- derived_heart[-individualfolds[[i]],]
      heart_test <- derived_heart[individualfolds[[i]],]
      
      # Try different number of predictors at split
      reg_rf_preds_tune <- list() 
      reg_rf_oob_error <- list()
      tree_num <- c(50, 250, 500)
      # There are 29 predictors
      m_num <- c( (6/2), 6)
      
      counter <- 1
      for(h in 1:length(tree_num)){
        for(j in 1:length(m_num)){
          reg_rf_preds_tune[[counter]] <- randomForest(Target~., heart_train,
                                                 ntree=tree_num[h], mtry=m_num[j])
          reg_rf_oob_error[[counter]] <-
            data.frame("tree_size"=tree_num[h],
                       "num_pred" =m_num[j],
                       "oob_error"=reg_rf_preds_tune[[counter]]$err.rate[tree_num[h]])
          counter <- counter+1
        }
      }
      
      reg_rf_oob_error_df <- do.call("rbind", reg_rf_oob_error)
      reg_rf_oob_error_df
      
      # Refit on training using best no. of predictors at split
      best_error <- which(reg_rf_oob_error_df$oob_error==min(reg_rf_oob_error_df$oob_error))
      reg_rf <- randomForest(Target~., heart_train,
                             ntree=reg_rf_oob_error_df$tree_size[best_error], mtry=reg_rf_oob_error_df$num_pred[best_error])
      
      # Evaluate on test set
      heart_test$rf_predict <- predict(reg_rf, newdata = heart_test)
     
      #Per-class accuracies
     per_class_accuracy[[i]] <- rep(NA, length(levels(heart_test$Target)))
      for(l in 1:length(per_class_accuracy[[i]])){
        per_class_accuracy[[i]][l] <- 
          heart_test %>%
          filter(Target==levels(Target)[l]) %>%
          summarise(error = 1-sum(rf_predict==levels(Target)[l])/n()) %>%
          unlist()
          
        names(per_class_accuracy[[i]])[l] <- 
          paste0("error_", levels(heart_test$Target)[l])
      }
  
    }
   data_set_list  <- as.data.frame(t(do.call("rbind", per_class_accuracy) %>%
      apply(MARGIN=2, FUN=mean, na.rm=TRUE)))
   
    data_set_list %>%
      flextable() %>% 
      colformat_num(digits=4) %>%
      add_header_lines(values="CV ERRORS PER CLASS")
    
   data_set_list_se <- as.data.frame(t(do.call("rbind", per_class_accuracy) %>%
      apply(MARGIN=2, FUN=sd, na.rm=TRUE))) 
   
    data_set_list_se %>%
      flextable() %>% 
      colformat_num(digits=4) %>%
      add_header_lines(values="CV ERROR SE PER CLASS")

```




``` {r}


plt <- ggplot(heart_data , aes(y=Resting_Blood_Pressure)) +
                 geom_boxplot() +
                 facet_wrap(~Target)
plt

heart_data2 <- heart_data %>% mutate(Target=factor(Target))
plt <- ggplot(heart_data2 , aes(x=Rest_ECG, fill=Target)) +
                 geom_bar() 
plt
```